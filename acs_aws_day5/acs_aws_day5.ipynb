{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ACS AWS Training: Day 5\n",
    "## Nathan Miles\n",
    "06/15/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"./endgame.jpg\" width=\"75%\" height=\"75%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline\n",
    "- Docker 101\n",
    "    - Containers\n",
    "- Example\n",
    "    - Create a lambda funciton that will,\n",
    "        - run SExtractor on an image to identify all sources,\n",
    "        - generate a catalog of photometry for all sources found in the image\n",
    "    - Create a deployment package containing the Lambda function and its dependencies using `EC2`\n",
    "        - `astropy`\n",
    "        - `matplotlib`\n",
    "        - `numpy`\n",
    "        - `scipy`\n",
    "        - `sep` (SExtractor in python)\n",
    "    - Uploading the deployment package to S3\n",
    "    - Building a Lambda function using deployment package\n",
    "    - Testing the function in the console\n",
    "    - Invoking the lambda function with `boto3`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Docker\n",
    "- Platform for containerizing applications\n",
    "- Containers are standardized units of software\n",
    "    - Packages up code and all its dependencies so it runs quickly and reliably in a variety computing environments\n",
    "        - code, runtime, system tools, system libraries and settings\n",
    "    - OS-level virtualization\n",
    "\n",
    "<center><figure><img src=\"visual_representation_of_a_container.png\" width=\"50%\" height=\"50%\" /><figcaption>Credit: <a href=\"https://www.docker.com/resources/what-container\">What is a Container?</a></figcaption></figure></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Overview\n",
    "- To circumvent any issues associated with installing/configuring Docker on your computer, we will build the deployment package on a small EC2 Instance.\n",
    "- In the example we will,\n",
    "    - build the deployment package on EC2,\n",
    "    - upload it to S3,\n",
    "    - create a Lambda function and specify the deployment package in S3 as the source code,\n",
    "    - test our Lambda function in the AWS Lambda Console,\n",
    "    - invoke our lambda function via `boto3`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Download the Software, Part 1\n",
    "#### Place the files in the following directory: `~/acs_aws_day5_code`\n",
    "- <a href=\"./day5_code/setup_ec2.sh\" download>setup_ec2.sh</a>\n",
    "    - Setup script from <a href=\"https://nmiles2718.github.io/presentations/acs_aws_day3/day3.html#/6\">Day 3</a>\n",
    "- <a href=\"./day5_code/build.sh\" download>build.sh</a>\n",
    "    - Build script used to create our deployment package\n",
    "- <a href=\"./day5_code/requirements.txt\" download>requirements.txt</a>\n",
    "    - `pip` requirements file specifying the packages to install\n",
    "- <a href=\"./day5_code/example_image_catalog.txt\" download>example_image_catalog.txt</a>\n",
    "    - Image catalog containing a list of images to be processed\n",
    "- <a href=\"./day5_code/extract_photometry.py\" download>extract_photometry.py</a>\n",
    "    - Python class for performing aperture photometry using Python wrapped \n",
    "        - <a href=\"https://sep.readthedocs.io/en/v1.0.x/\">sep.readthedocs.io</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Download the Software, Part 2\n",
    "#### Place the files in the following directory: `~/acs_aws_day5_code`\n",
    "- <a href=\"./day5_code/datavis.py\" download>datavis.py</a>\n",
    "    - Convenience class for handling all data visualization \n",
    "- <a href=\"./day5_code/aws_source_extraction.py\" download>aws_source_extraction.py</a>\n",
    "    - Python module for running source extraction on AWS\n",
    "    - This is the file that contains the `handler` for the Lambda function\n",
    "- <a href=\"./day5_code/run_photometry.py\" download>run_photometry.py</a>\n",
    "    - Python module for invoking the Lambda function via `boto3`\n",
    "- <a href=\"./day5_code/launch_instance.py\" download>launch_instance.py</a>\n",
    "    - Launch an EC2 instance using a specified launch template and key pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Building the deployment package, Part 1\n",
    "- Change directory into `~/acs_aws_day5_code`\n",
    "- Launch an EC2 template to use for creating the Docker container. \n",
    "    - For `TEMPATE_ID`, use `lt-0e86f881efd781a45`\n",
    "    - For `KEYNAME` argument, exclude the `.pem` suffix \n",
    "    \n",
    "\n",
    "``` console\n",
    "python launch_instance.py -template_id <TEMPLATE_ID> -keyname <KEYNAME>\n",
    "```\n",
    "\n",
    "- Copy over the `acs_aws_day5_code` directory to the home directory (`~/`) of your EC2 instance\n",
    "\n",
    "```console\n",
    "scp -ri \"path/to/key.pem\" ~/acs_aws_day5_code ec2-user@public_dns:~\n",
    "```\n",
    "\n",
    "- Use `setup_ec2.sh` to upload your AWS access keys\n",
    "    - For `KEYNAME`, include the `.pem` suffix\n",
    "```console\n",
    "bash setup_ec2.sh <EC2 Public DNS> <KEYNAME>\n",
    "```\n",
    "\n",
    "\n",
    "- Install and configure docker,\n",
    "    - install: `sudo yum install docker`\n",
    "    - start docker: `sudo service docker start`\n",
    "    - set permissions: `sudo usermod -a -G docker ec2-user`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Building the deployment package, Part 2\n",
    "- Log out of the EC2 instance\n",
    "- Log back in and execute the command: `docker info`\n",
    "    - If no output is shown, your docker installation failed\n",
    "- Change directory to `~/acs_aws_day5_code`\n",
    "- Execute the following commands to the build the `zip` file\n",
    "    - `docker pull amazonlinux:2018.03`\n",
    "        - Amazon Linux image that we use to build our deployment package in\n",
    "    - `docker run -v $(pwd):/outputs -it amazonlinux:2018.03 /bin/bash /outputs/build.sh`\n",
    "        - The deployment package is the `venv.zip` file\n",
    "- While the docker command is running, create an S3 bucket\n",
    "- Copy the deployment package from EC2 to S3\n",
    "    - `aws s3 cp ./venv.zip s3://<YOUR BUCKET NAME>`\n",
    "    - Replace `<YOUR BUCKET NAME>` with the name of the bucket you created in the previous step\n",
    "- Navigate to your S3 bucket in the console and make sure your `zip` file was properly uploaded\n",
    "    - Select the `venv.zip` file and click **\"Copy path\"**\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Creating the Lambda function\n",
    "- Navigate to the AWS Lambda Console\n",
    "- Click **\"Create Function\"**\n",
    "    - Function name: whatever you want\n",
    "    - Runtime: `Python 3.6`\n",
    "    - Choose or create an execution role:\n",
    "        - Select **\"Use an Existing Role\"** --> `acs-aws-lambda`\n",
    "- In the **Function code** section of the Lambda Console, select the **Actions** menu:\n",
    "    - Choose **\"Upload a file from Amazon S3\"**\n",
    "    - Paste the S3 path to your `venv.zip` file \n",
    "- Navigate to the **\"Basic Settings\"** block on the AWS Lambda console, click **\"Edit\"** and update the following,\n",
    "    - Handler: `aws_source_extraction.handler`\n",
    "    - Memory: 1600 MB\n",
    "    - Timeout: 1 minute\n",
    "    - Click **\"Save\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Configure a test event for the Lambda function\n",
    "- Create a test event for your lambda function in the AWS Lambda console\n",
    "- Copy and paste the test below making sure to update the \"s3_output_bucket\" to point to the bucket you created\n",
    "\n",
    "```python\n",
    "{\n",
    "  \"fits_s3_key\": \"testsdatangc104_crj.fits\",\n",
    "  \"fits_s3_bucket\": \"test-data-day5\",\n",
    "  \"radius\": 3,\n",
    "  \"r_inner\": 14,\n",
    "  \"r_outer\": 16,\n",
    "  \"s3_output_bucket\": <YOUR BUCKET NAME>\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Invoke the lambda with `boto3`\n",
    "- On your local machine, change directory to `~/acs_aws_day5_code`\n",
    "- Execute the following,\n",
    "\n",
    "```console\n",
    "python run_photometry.py -catalog example_image_catalog.txt -lambda_name <YOUR LAMBDA NAME> -output_bucket <YOUR S3 BUCKET>\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
